{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Check for Missing Values","metadata":{}},{"cell_type":"markdown","source":"This script below checks whether each folder in the PTB-XL ECG image dataset contains the expected number of image files (each ending in _lr-0.png). All folders from 00000 to 20000 are expected to have 1000 files each, except for the folder 21000, which is expected to contain 838 files (from 21000 to 21837). It reports any folders that are missing files.","metadata":{}},{"cell_type":"code","source":"# The original dataset can be accessed here: https://physionet.org/content/ptb-xl/1.0.3/\n# Kaggle version available at: https://www.kaggle.com/datasets/khyeh0719/ptb-xl-dataset\n\ndef check_missing_files_in_folders(base_path):\n    folders_with_missing_files = []\n\n    # Loop through folders named '00000', '01000', ..., up to '20000'\n    for folder_num in range(0, 21000, 1000):  # The last standard folder is 21000\n        folder_name = f\"{folder_num:05d}\"  # Format number with leading zeros (e.g., '00000')\n        folder_path = os.path.join(base_path, folder_name)\n        \n        if os.path.exists(folder_path):\n            # Count the number of image files ending with '_lr-0.png' in the folder\n            file_count = len([f for f in os.listdir(folder_path) if f.endswith(\"_lr-0.png\")])\n            # If the folder has less than 1000 files, add it to the list of problematic folders\n            if file_count < 1000:\n                folders_with_missing_files.append(folder_name)\n        else:\n            # Print a message if the folder does not exist\n            print(f\"Folder {folder_name} not found!\")\n\n    # Special handling for folder '21000', which contains files from 21000 to 21837 (total 838 files expected)\n    folder_21000_path = os.path.join(base_path, \"21000\")\n    if os.path.exists(folder_21000_path):\n        # Generate the set of expected filenames in '21000'\n        expected_files = {f\"{i:05d}_lr-0.png\" for i in range(21000, 21838)}  # Files: 21000_lr-0.png to 21837_lr-0.png\n        # Get the set of actual files in the folder\n        existing_files = set(os.listdir(folder_21000_path))\n        # Identify missing files by set difference\n        missing_files = expected_files - existing_files\n        if missing_files:\n            folders_with_missing_files.append(\"21000\")\n    \n    return folders_with_missing_files\n\n# Define the path to the base directory containing all folders\nbase_path = \"/kaggle/input/ptb-xl-ecg-image-gmc2024\"\n# Check for folders that have fewer image files than expected\nmissing_folders = check_missing_files_in_folders(base_path)\n# Print the result\nif missing_folders:\n    print(\"Folders with missing files detected:\")\n    for folder in missing_folders:\n        print(f\"Folder {folder}\")\nelse:\n    print(\"All folders contain 1,000 or more files.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This script below is used to identify missing image files in a specific folder of the PTB-XL ECG image dataset, specifically the folder named 00000. Each file in the dataset follows a sequential naming convention such as 00001_lr-0.png, 00002_lr-0.png, and so on. The script generates a list of all expected filenames within a given range (from 00001 to 00999 in this case), then compares it with the actual files present in the folder. By calculating the difference between the expected and existing files, the script identifies which files are missing. It then prints out the total number of missing files along with their specific filenames. ","metadata":{}},{"cell_type":"code","source":"def find_missing_files(folder_path, start_num, end_num):\n    # List of files that are expected to be present\n    expected_files = {f\"{i:05d}_lr-0.png\" for i in range(start_num, end_num + 1)}\n    # List of files that currently exist in the folder\n    existing_files = set(os.listdir(folder_path))\n    # Find the missing files by subtracting the sets\n    missing_files = expected_files - existing_files\n    return sorted(missing_files)\n\n# Path to folder '00000'\nfolder_path = \"/kaggle/input/ptb-xl-ecg-image-gmc2024/00000\"\n\n# Expected range of file numbers\nstart_num = 1    # Because the first expected file is 00001\nend_num = 999    # Because the last expected file is 00999\n\n# Find the missing files in the folder\nmissing_files = find_missing_files(folder_path, start_num, end_num)\n\n# Display the result\nprint(f\"Number of missing files: {len(missing_files)}\")\nprint(\"Missing files:\")\nfor file in missing_files:\n    print(file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_missing_files(folder_path, start_num, end_num):\n    # List of files that are expected to be present\n    expected_files = {f\"{i:05d}_lr-0.png\" for i in range(start_num, end_num + 1)}\n    # List of files that currently exist in the folder\n    existing_files = set(os.listdir(folder_path))\n    # Find missing files by comparing expected and existing files\n    missing_files = expected_files - existing_files\n    return sorted(missing_files)\n\n# Path to folder '02000'\nfolder_path = \"/kaggle/input/ptb-xl-ecg-image-gmc2024/02000\"\n\n# Expected range of file numbers\nstart_num = 2000   # Because the first expected file is 02000\nend_num = 2999     # Because the last expected file is 02999\n\n# Find missing files in the folder\nmissing_files = find_missing_files(folder_path, start_num, end_num)\n\n# Display the results\nprint(f\"Number of missing files: {len(missing_files)}\")\nprint(\"Missing files:\")\nfor file in missing_files:\n    print(file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This script checks for missing ECG image files in a specific folder (02000) of the PTB-XL dataset. Each image file follows a consistent naming pattern such as 02000_lr-0.png to 02999_lr-0.png, which corresponds to numerical identifiers from 2000 to 2999. The script generates the full list of expected filenames within that range and compares it with the actual files found in the folder. It identifies any missing files and prints out both the total number of missing files and their specific names. This verification process is typically repeated for all folders in the dataset, starting from 00000, 01000, 02000, and so on, in increments of 1000, up to the folder 20000. ","metadata":{}},{"cell_type":"markdown","source":"# Lowercase and Translation Process","metadata":{}},{"cell_type":"code","source":"# Overview of the entire CSV file\nptbxlcsv_path = '/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/ptbxl_database.csv'\nptbxl = pd.read_csv(ptbxlcsv_path)\nptbxl.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print the number of rows in the dataset\nprint(f\"Number of rows: {ptbxl.shape[0]}\")\n# Print the number of columns in the dataset\nprint(f\"Number of columns: {ptbxl.shape[1]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the columns/features in the dataset\nprint(\"Columns/features in the dataset:\")\nprint(ptbxl.columns)\n\n# Display the number of missing values in each column (overall)\nprint(\"\\nNumber of missing values in each column:\")\nprint(ptbxl.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Focus on ECG ID, File Name (filename_lr), and Caption (report)\nptbxl[['ecg_id', 'filename_lr', 'report']].head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rename the columns: 'ecg_id' to 'id', 'filename_lr' to 'name', and 'report' to 'caption'\nptbxl = ptbxl.rename(columns={'ecg_id': 'id', 'filename_lr': 'name', 'report': 'caption'})\n# Keep only the 'id', 'name', and 'caption' columns in the dataset\nptbxl = ptbxl[['id', 'name', 'caption']]\n# Display the first few rows of the updated dataset\nptbxl.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a function to generate the full image path for each row\ndef generate_image_path(row):\n    folder = row['name'].split('/')[1][:5]  # Extract the folder name from the 'name' column\n    return f\"/kaggle/input/ptb-xl-ecg-image-gmc2024/{folder}/{row['name'].split('/')[-1]}-0.png\"\n\n# Apply the function to each row to create a new 'images' column with the full image path\nptbxl['images'] = ptbxl.apply(generate_image_path, axis=1)\n# Convert all text in the 'caption' column to lowercase\nptbxl['caption'] = ptbxl['caption'].str.lower()\n# Keep only the relevant columns in the DataFrame\nptbxl = ptbxl[['id', 'name', 'caption', 'images']]\n# Display the first 11 rows of the updated dataset\nptbxl.head(11)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Manually input the list of missing files that were previously inspected\nmissing_files = [\n    \"00137_lr-0.png\", \"00139_lr-0.png\", \"00140_lr-0.png\", \"00141_lr-0.png\", \n    \"00142_lr-0.png\", \"00143_lr-0.png\", \"00145_lr-0.png\", \"00456_lr-0.png\", \n    \"00458_lr-0.png\", \"00459_lr-0.png\", \"00461_lr-0.png\", \"00462_lr-0.png\", \n    \"02506_lr-0.png\", \"02511_lr-0.png\", \"03795_lr-0.png\", \"03798_lr-0.png\", \n    \"03800_lr-0.png\", \"03801_lr-0.png\", \"03832_lr-0.png\", \"05817_lr-0.png\", \n    \"07777_lr-0.png\", \"07779_lr-0.png\", \"07782_lr-0.png\", \"09821_lr-0.png\", \n    \"09825_lr-0.png\", \"09888_lr-0.png\", \"11810_lr-0.png\", \"11814_lr-0.png\", \n    \"11815_lr-0.png\", \"11817_lr-0.png\", \"11838_lr-0.png\", \"13791_lr-0.png\", \n    \"13793_lr-0.png\", \"13796_lr-0.png\", \"13797_lr-0.png\", \"13799_lr-0.png\", \n    \"15742_lr-0.png\", \"17872_lr-0.png\", \"17873_lr-0.png\", \"17874_lr-0.png\", \n    \"17875_lr-0.png\", \"17876_lr-0.png\", \"17877_lr-0.png\", \"17878_lr-0.png\",\n    \"17879_lr-0.png\", \"17880_lr-0.png\", \"17881_lr-0.png\", \"17882_lr-0.png\",\n    \"17883_lr-0.png\", \"17884_lr-0.png\", \"17885_lr-0.png\", \"17886_lr-0.png\",\n    \"17887_lr-0.png\", \"17888_lr-0.png\", \"17889_lr-0.png\", \"17890_lr-0.png\",\n    \"17891_lr-0.png\", \"17892_lr-0.png\", \"17893_lr-0.png\", \"17894_lr-0.png\",\n    \"17895_lr-0.png\", \"17896_lr-0.png\", \"17897_lr-0.png\", \"17898_lr-0.png\",\n    \"17899_lr-0.png\", \"17900_lr-0.png\", \"17901_lr-0.png\", \"17902_lr-0.png\",\n    \"17903_lr-0.png\", \"17904_lr-0.png\", \"17905_lr-0.png\", \"17906_lr-0.png\",\n    \"17907_lr-0.png\", \"17908_lr-0.png\", \"17909_lr-0.png\", \"17910_lr-0.png\",\n    \"17911_lr-0.png\", \"17912_lr-0.png\", \"17913_lr-0.png\", \"17914_lr-0.png\",\n    \"17915_lr-0.png\", \"17916_lr-0.png\", \"17917_lr-0.png\", \"17918_lr-0.png\",\n    \"17919_lr-0.png\", \"17920_lr-0.png\", \"17921_lr-0.png\", \"17922_lr-0.png\",\n    \"17923_lr-0.png\", \"17924_lr-0.png\", \"17925_lr-0.png\", \"17926_lr-0.png\",\n    \"17927_lr-0.png\", \"17928_lr-0.png\", \"17929_lr-0.png\", \"17930_lr-0.png\",\n    \"17931_lr-0.png\", \"17932_lr-0.png\", \"17933_lr-0.png\", \"17934_lr-0.png\",\n    \"17935_lr-0.png\", \"17936_lr-0.png\", \"17937_lr-0.png\", \"17938_lr-0.png\",\n    \"17939_lr-0.png\", \"17940_lr-0.png\", \"17941_lr-0.png\", \"17942_lr-0.png\",\n    \"17943_lr-0.png\", \"17944_lr-0.png\", \"17945_lr-0.png\", \"17946_lr-0.png\",\n    \"17947_lr-0.png\", \"17948_lr-0.png\", \"17949_lr-0.png\", \"17950_lr-0.png\",\n    \"17951_lr-0.png\", \"17952_lr-0.png\", \"17953_lr-0.png\", \"17954_lr-0.png\",\n    \"17955_lr-0.png\", \"17956_lr-0.png\", \"17957_lr-0.png\", \"17958_lr-0.png\",\n    \"17959_lr-0.png\", \"17960_lr-0.png\", \"17961_lr-0.png\", \"17962_lr-0.png\",\n    \"17963_lr-0.png\", \"17964_lr-0.png\", \"17965_lr-0.png\", \"17966_lr-0.png\",\n    \"17967_lr-0.png\", \"17968_lr-0.png\", \"17969_lr-0.png\", \"17970_lr-0.png\",\n    \"17971_lr-0.png\", \"17972_lr-0.png\", \"17973_lr-0.png\", \"17974_lr-0.png\",\n    \"17975_lr-0.png\", \"17976_lr-0.png\", \"17977_lr-0.png\", \"17978_lr-0.png\",\n    \"17979_lr-0.png\", \"17980_lr-0.png\", \"17981_lr-0.png\", \"17982_lr-0.png\",\n    \"17983_lr-0.png\", \"17984_lr-0.png\", \"17985_lr-0.png\", \"17986_lr-0.png\",\n    \"17987_lr-0.png\", \"17988_lr-0.png\", \"17989_lr-0.png\", \"17990_lr-0.png\",\n    \"17991_lr-0.png\", \"17992_lr-0.png\", \"17993_lr-0.png\", \"17994_lr-0.png\",\n    \"17995_lr-0.png\", \"17996_lr-0.png\", \"17997_lr-0.png\", \"17998_lr-0.png\",\n    \"17999_lr-0.png\", \"18150_lr-0.png\",\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Number of rows in the cleaned DataFrame\njumlah_baris = ptbxl_cleaned.shape[0]\nprint(f\"Number of rows after cleaning: {jumlah_baris}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modify the 'name' column to match the PNG file naming format used in the image dataset\nptbxl_cleaned.loc[:, 'name'] = (\n    ptbxl_cleaned['name'].str.split('/').str[-1].str.rstrip('-0.png') + '-0.png'\n)\n\n# Display the first 11 rows of the result\nptbxl_cleaned.head(11)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install deep-translator","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from deep_translator import GoogleTranslator\nfrom tqdm import tqdm\n\n# Initialize tqdm for pandas to show a progress bar\ntqdm.pandas()\n\n# Create a copy to avoid SettingWithCopyWarning\nptbxl_cleaned = ptbxl_cleaned.copy()\n\n# Translate the 'caption' column from German to English with a progress bar\nptbxl_cleaned['caption_en'] = ptbxl_cleaned['caption'].progress_apply(\n    lambda x: GoogleTranslator(source='de', target='en').translate(x)\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove the old 'caption' column\nptbxl_cleaned.drop(columns=['caption'], inplace=True)\n\n# Rename the 'caption_en' column to 'caption'\nptbxl_cleaned.rename(columns={'caption_en': 'caption'}, inplace=True)\n\n# Display the first 11 rows of the updated DataFrame\nptbxl_cleaned.head(11)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the translated DataFrame to a CSV file\nptbxl_cleaned.to_csv('/kaggle/working/ptbxl_translated.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Standardization of Medical (ECG) Terms and Removal of Punctuation","metadata":{}},{"cell_type":"markdown","source":"The file `ptbxl_translated.csv` was originally saved in the Kaggle working directory. It was downloaded and then uploaded as input in the Kaggle Notebook.","metadata":{}},{"cell_type":"code","source":"# Define the new path where the translated CSV is stored in Kaggle input\ntranslated_csv_path = '/kaggle/input/ptbxl_translated.csv'\n# Read the CSV file into a DataFrame\nptbxl_translated = pd.read_csv(translated_csv_path)\n# Display the first few rows\nptbxl_translated.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\n# List of abbreviations to check\nabbreviations = [\"@\", \"+\", \"&\", \"pac\", \"pacs\", \"sve\", \"sves\", \"apc\", \"apcs\", \n                 \"pvc\", \"pvcs\", \"vpc\", \"vpcs\", \"ves\", \"ectopic\", \"ectopics\", \"ectopy\",\n                 \"brady\", \"sb\", \"tachy\", \"tachycardia\", \"st\", \"svt\", \"nsvt\", \"sr\", \"nsr\",\n                 \"af\", \"afib\", \"a-fib\", \"afl\", \"a-flutter\", \"aflutter\", \"cw\", \"rvr\", \"ppm\",\n                 \"bpm\", \"pat\", \"pt\", \"bts\", \"wo\", \"w/o\", \"w\", \"w/\", \"hr\", \"avb\"]\n\n# Escape special characters for regex\nescaped_abbreviations = [re.escape(abbr) for abbr in abbreviations]\n\n# Create a dictionary to store the number of occurrences of each abbreviation\nabbreviation_counts = {abbr: ptbxl[\"caption\"].str.contains(rf\"\\b{escaped}\\b\", case=False, na=False).sum()\n                       for abbr, escaped in zip(abbreviations, escaped_abbreviations)}\n\n# Show only abbreviations that are present in the dataset\nabbreviation_counts = {abbr: count for abbr, count in abbreviation_counts.items() if count > 0}\nfor abbr, count in abbreviation_counts.items():\n    print(f\"{abbr}: found {count} times\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"abbreviation_dict = {\n    \"@\": \"at\",\n    \"+\": \"and\", \"&\": \"and\",\n    \"pac\": \"premature atrial contraction\", \"pacs\": \"premature atrial contraction\", \"sve\": \"premature atrial contraction\", \"sves\": \"premature atrial contraction\",\n    \"apc\": \"premature atrial contraction\", \"apcs\": \"premature atrial contraction\",\n    \"pvc\": \"premature ventricular contraction\", \"pvcs\": \"premature ventricular contraction\",\n    \"vpc\": \"premature ventricular contraction\", \"vpcs\": \"premature ventricular contraction\", \"ves\": \"premature ventricular contraction\",\n    \"ectopic\": \"premature contraction\", \"ectopics\": \"premature contraction\", \"ectopy\": \"premature contraction\",\n    \"brady\": \"bradycardia\",\n    \"sb\": \"sinus bradycardia\",\n    \"tachy\": \"tachycardia\", \"tachycardia\": \"tachycardia\",\n    \"st\": \"sinus tachycardia\",\n    \"svt\": \"supraventricular tachycardia\",\n    \"nsvt\": \"nonsustained ventricular tachycardia\",\n    \"sr\": \"sinus rhythm\",\n    \"nsr\": \"normal sinus rhythm\",\n    \"af\": \"atrial fibrillation\", \"afib\": \"atrial fibrillation\", \"a-fib\": \"atrial fibrillation\",\n    \"afl\": \"atrial flutter\", \"a-flutter\": \"atrial flutter\", \"aflutter\": \"atrial flutter\",\n    \"cw\": \"continuous wave\",\n    \"rvr\": \"rapid ventricular rate\",\n    \"ppm\": \"permanent pacemaker\",\n    \"bpm\": \"beats per minute\",\n    \"pat\": \"patient\", \"pt\": \"patient\",\n    \"bts\": \"beats\",\n    \"wo\": \"without\", \"w/o\": \"without\",\n    \"w\": \"with\", \"w/\": \"with\",\n    \"hr\": \"heart rate\",\n    \"avb\": \"atrioventricular block\"\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef replace_abbreviations(text, abbrev_dict):\n    words = text.split()  # Split text into a list of words\n    replaced_words = [abbrev_dict[word.lower()] if word.lower() in abbrev_dict else word for word in words]\n    return \" \".join(replaced_words)\n\nptbxl['caption'] = ptbxl['caption'].apply(lambda x: replace_abbreviations(x, abbreviation_dict))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import string\n\n# Create a regex pattern of all punctuation except hyphen (-)\npunct_to_remove = string.punctuation.replace('-', '')  # keep hyphen\nregex_pattern = f\"[{re.escape(punct_to_remove)}]\"\n\n# Find all unique punctuation characters in the caption column (excluding hyphens)\nunique_punctuations = set()\nfor caption in ptbxl['caption'].dropna():\n    punct_in_caption = re.findall(rf\"[{re.escape(punct_to_remove + '-')}]\",\n                                  caption)\n    unique_punctuations.update(punct_in_caption)\n\nprint(\"Unique punctuation marks found (including hyphens):\", unique_punctuations)\n\n# Remove all punctuation except hyphens from captions\nptbxl['caption'] = ptbxl['caption'].apply(lambda x: re.sub(regex_pattern, '', x) if isinstance(x, str) else x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_csv_path = 'ptbxlengfinal.csv'\nptbxl.to_csv(output_csv_path, index=False)\nprint(f\"CSV saved successfully as {output_csv_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}